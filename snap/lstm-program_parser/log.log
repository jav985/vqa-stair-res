{'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': './snap/lstm-program_parser/log.log', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './snap/lstm-program_parser/runs', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': 'raw', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 100, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './snap/lstm-program_parser', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 100, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 10, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=True, log_interval=100, log_format=None, log_file='./snap/lstm-program_parser/log.log', aim_repo=None, aim_run_hash=None, tensorboard_logdir='./snap/lstm-program_parser/runs', wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer='space', bpe=None, optimizer='adam', lr_scheduler='fixed', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=16, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl='raw', data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=100, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=16, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='lstm', max_epoch=5, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./snap/lstm-program_parser', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=100, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, share_decoder_input_output_embed=False, share_all_embeddings=False, data='data/AGQA/AGQA2_fairseq/data-bin/AGQA2', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, pad=1, eos=2, unk=3, encoder_layers=2, decoder_layers=2, dropout=0.2, no_seed_provided=False, encoder_embed_dim=512, encoder_embed_path=None, encoder_freeze_embed=False, encoder_hidden_size=512, encoder_bidirectional=False, encoder_dropout_in=0.2, encoder_dropout_out=0.2, decoder_embed_dim=512, decoder_embed_path=None, decoder_freeze_embed=False, decoder_hidden_size=512, decoder_out_embed_dim=512, decoder_attention='1', decoder_dropout_in=0.2, decoder_dropout_out=0.2, adaptive_softmax_cutoff='10000,50000,200000', _name='lstm'), 'task': {'_name': 'translation', 'data': 'data/AGQA/AGQA2_fairseq/data-bin/AGQA2', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': raw, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': {'_name': 'space'}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
LSTMModel(
  (encoder): LSTMEncoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(272, 512, padding_idx=1)
    (lstm): LSTM(512, 512, num_layers=2, dropout=0.2)
  )
  (decoder): LSTMDecoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(248, 512, padding_idx=1)
    (layers): ModuleList(
      (0): LSTMCell(1024, 512)
      (1): LSTMCell(512, 512)
    )
    (attention): AttentionLayer(
      (input_proj): Linear(in_features=512, out_features=512, bias=False)
      (output_proj): Linear(in_features=1024, out_features=512, bias=False)
    )
    (fc_out): Linear(in_features=512, out_features=248, bias=True)
  )
)
task: TranslationTask
model: LSTMModel
criterion: CrossEntropyCriterion
num. shared model params: 10,633,464 (num. trained: 10,633,464)
num. expert model params: 0 (num. trained: 0)
training on 1 devices (GPUs/TPUs)
max tokens per device = None and max sentences per device = 16
Start iterating over samples
{'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': './snap/lstm-program_parser/log.log', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './snap/lstm-program_parser/runs', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': 'raw', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 100, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './snap/lstm-program_parser', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 100, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 10, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=True, log_interval=100, log_format=None, log_file='./snap/lstm-program_parser/log.log', aim_repo=None, aim_run_hash=None, tensorboard_logdir='./snap/lstm-program_parser/runs', wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer='space', bpe=None, optimizer='adam', lr_scheduler='fixed', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=16, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl='raw', data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=100, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=16, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='lstm', max_epoch=5, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./snap/lstm-program_parser', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=100, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, share_decoder_input_output_embed=False, share_all_embeddings=False, data='data/AGQA/AGQA2_fairseq/data-bin/AGQA2', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, pad=1, eos=2, unk=3, encoder_layers=2, decoder_layers=2, dropout=0.2, no_seed_provided=False, encoder_embed_dim=512, encoder_embed_path=None, encoder_freeze_embed=False, encoder_hidden_size=512, encoder_bidirectional=False, encoder_dropout_in=0.2, encoder_dropout_out=0.2, decoder_embed_dim=512, decoder_embed_path=None, decoder_freeze_embed=False, decoder_hidden_size=512, decoder_out_embed_dim=512, decoder_attention='1', decoder_dropout_in=0.2, decoder_dropout_out=0.2, adaptive_softmax_cutoff='10000,50000,200000', _name='lstm'), 'task': {'_name': 'translation', 'data': 'data/AGQA/AGQA2_fairseq/data-bin/AGQA2', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': raw, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': {'_name': 'space'}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
LSTMModel(
  (encoder): LSTMEncoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(272, 512, padding_idx=1)
    (lstm): LSTM(512, 512, num_layers=2, dropout=0.2)
  )
  (decoder): LSTMDecoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(248, 512, padding_idx=1)
    (layers): ModuleList(
      (0): LSTMCell(1024, 512)
      (1): LSTMCell(512, 512)
    )
    (attention): AttentionLayer(
      (input_proj): Linear(in_features=512, out_features=512, bias=False)
      (output_proj): Linear(in_features=1024, out_features=512, bias=False)
    )
    (fc_out): Linear(in_features=512, out_features=248, bias=True)
  )
)
task: TranslationTask
model: LSTMModel
criterion: CrossEntropyCriterion
num. shared model params: 10,633,464 (num. trained: 10,633,464)
num. expert model params: 0 (num. trained: 0)
training on 1 devices (GPUs/TPUs)
max tokens per device = None and max sentences per device = 16
Start iterating over samples
epoch 001:    100 / 900 loss=4.903, ppl=29.91, wps=4140.7, ups=15.25, wpb=272.3, bsz=16, num_updates=100, lr=0.0005, gnorm=2.227, train_wall=7, gb_free=1.4, wall=8
begin validation on "valid" subset
epoch 001 | valid on 'valid' subset | loss 3.772 | ppl 13.66 | wps 17549.3 | wpb 264.7 | bsz 16 | num_updates 100
epoch 001:    200 / 900 loss=2.6, ppl=6.06, wps=1198.4, ups=4.32, wpb=277.6, bsz=16, num_updates=200, lr=0.0005, gnorm=1.683, train_wall=21, gb_free=1.4, wall=31
begin validation on "valid" subset
epoch 001 | valid on 'valid' subset | loss 2.162 | ppl 4.48 | wps 17511 | wpb 264.7 | bsz 16 | num_updates 200 | best_loss 2.162
epoch 001:    300 / 900 loss=2.042, ppl=4.12, wps=2988.4, ups=12.37, wpb=241.7, bsz=16, num_updates=300, lr=0.0005, gnorm=1.574, train_wall=6, gb_free=1.4, wall=39
begin validation on "valid" subset
epoch 001 | valid on 'valid' subset | loss 1.78 | ppl 3.43 | wps 17984.1 | wpb 264.7 | bsz 16 | num_updates 300 | best_loss 1.78
{'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': './snap/lstm-program_parser/log.log', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './snap/lstm-program_parser/runs', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': 'raw', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 900, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './snap/lstm-program_parser', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 900, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 10, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=True, log_interval=100, log_format=None, log_file='./snap/lstm-program_parser/log.log', aim_repo=None, aim_run_hash=None, tensorboard_logdir='./snap/lstm-program_parser/runs', wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer='space', bpe=None, optimizer='adam', lr_scheduler='fixed', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=16, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl='raw', data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=900, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=16, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='lstm', max_epoch=5, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./snap/lstm-program_parser', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=900, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, share_decoder_input_output_embed=False, share_all_embeddings=False, data='data/AGQA/AGQA2_fairseq/data-bin/AGQA2', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, pad=1, eos=2, unk=3, encoder_layers=2, decoder_layers=2, dropout=0.2, no_seed_provided=False, encoder_embed_dim=512, encoder_embed_path=None, encoder_freeze_embed=False, encoder_hidden_size=512, encoder_bidirectional=False, encoder_dropout_in=0.2, encoder_dropout_out=0.2, decoder_embed_dim=512, decoder_embed_path=None, decoder_freeze_embed=False, decoder_hidden_size=512, decoder_out_embed_dim=512, decoder_attention='1', decoder_dropout_in=0.2, decoder_dropout_out=0.2, adaptive_softmax_cutoff='10000,50000,200000', _name='lstm'), 'task': {'_name': 'translation', 'data': 'data/AGQA/AGQA2_fairseq/data-bin/AGQA2', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': raw, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': {'_name': 'space'}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
LSTMModel(
  (encoder): LSTMEncoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(272, 512, padding_idx=1)
    (lstm): LSTM(512, 512, num_layers=2, dropout=0.2)
  )
  (decoder): LSTMDecoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(248, 512, padding_idx=1)
    (layers): ModuleList(
      (0): LSTMCell(1024, 512)
      (1): LSTMCell(512, 512)
    )
    (attention): AttentionLayer(
      (input_proj): Linear(in_features=512, out_features=512, bias=False)
      (output_proj): Linear(in_features=1024, out_features=512, bias=False)
    )
    (fc_out): Linear(in_features=512, out_features=248, bias=True)
  )
)
task: TranslationTask
model: LSTMModel
criterion: CrossEntropyCriterion
num. shared model params: 10,633,464 (num. trained: 10,633,464)
num. expert model params: 0 (num. trained: 0)
training on 1 devices (GPUs/TPUs)
max tokens per device = None and max sentences per device = 16
Start iterating over samples
epoch 001:    100 / 900 loss=4.903, ppl=29.91, wps=4164.4, ups=15.34, wpb=272.3, bsz=16, num_updates=100, lr=0.0005, gnorm=2.227, train_wall=7, gb_free=1.4, wall=8
epoch 001:    200 / 900 loss=2.6, ppl=6.06, wps=1425.3, ups=5.13, wpb=277.6, bsz=16, num_updates=200, lr=0.0005, gnorm=1.683, train_wall=19, gb_free=1.4, wall=28
epoch 001:    300 / 900 loss=2.042, ppl=4.12, wps=4153.7, ups=17.19, wpb=241.7, bsz=16, num_updates=300, lr=0.0005, gnorm=1.574, train_wall=6, gb_free=1.4, wall=33
epoch 001:    400 / 900 loss=1.701, ppl=3.25, wps=4340.3, ups=15.5, wpb=279.9, bsz=16, num_updates=400, lr=0.0005, gnorm=1.154, train_wall=6, gb_free=1.4, wall=40
epoch 001:    500 / 900 loss=1.497, ppl=2.82, wps=4092.1, ups=17.18, wpb=238.1, bsz=16, num_updates=500, lr=0.0005, gnorm=1.214, train_wall=6, gb_free=1.4, wall=46
epoch 001:    600 / 900 loss=1.216, ppl=2.32, wps=4364, ups=15.89, wpb=274.6, bsz=16, num_updates=600, lr=0.0005, gnorm=0.998, train_wall=6, gb_free=1.4, wall=52
epoch 001:    700 / 900 loss=1.062, ppl=2.09, wps=3929.1, ups=16.55, wpb=237.4, bsz=16, num_updates=700, lr=0.0005, gnorm=0.855, train_wall=6, gb_free=1.4, wall=58
epoch 001:    800 / 900 loss=0.89, ppl=1.85, wps=4306.7, ups=15.71, wpb=274.2, bsz=16, num_updates=800, lr=0.0005, gnorm=0.878, train_wall=6, gb_free=1.4, wall=64
epoch 001:    900 / 900 loss=0.815, ppl=1.76, wps=4265.6, ups=16.31, wpb=261.6, bsz=16, num_updates=900, lr=0.0005, gnorm=0.871, train_wall=6, gb_free=1.4, wall=71
begin validation on "valid" subset
epoch 001 | valid on 'valid' subset | loss 0.719 | ppl 1.65 | wps 17838.9 | wpb 264.7 | bsz 16 | num_updates 900
end of epoch 1 (average epoch stats below)
epoch 001 | loss 1.878 | ppl 3.67 | wps 3333.1 | ups 12.73 | wpb 261.9 | bsz 16 | num_updates 900 | lr 0.0005 | gnorm 1.272 | train_wall 68 | gb_free 1.4 | wall 72
Start iterating over samples
epoch 002:    100 / 900 loss=0.626, ppl=1.54, wps=3352.9, ups=12.63, wpb=265.6, bsz=16, num_updates=1000, lr=0.0005, gnorm=0.779, train_wall=6, gb_free=1.4, wall=78
epoch 002:    100 / 900 loss=0.626, ppl=1.54, wps=3352.9, ups=12.63, wpb=265.6, bsz=16, num_updates=1000, lr=0.0005, gnorm=0.779, train_wall=6, gb_free=1.4, wall=78
epoch 002:    200 / 900 loss=0.569, ppl=1.48, wps=4179.3, ups=14.91, wpb=280.2, bsz=16, num_updates=1100, lr=0.0005, gnorm=0.798, train_wall=7, gb_free=1.4, wall=85
epoch 002:    200 / 900 loss=0.569, ppl=1.48, wps=4179.3, ups=14.91, wpb=280.2, bsz=16, num_updates=1100, lr=0.0005, gnorm=0.798, train_wall=7, gb_free=1.4, wall=85
epoch 002:    300 / 900 loss=0.455, ppl=1.37, wps=4084.1, ups=17.34, wpb=235.6, bsz=16, num_updates=1200, lr=0.0005, gnorm=0.775, train_wall=6, gb_free=1.4, wall=91
epoch 002:    300 / 900 loss=0.455, ppl=1.37, wps=4084.1, ups=17.34, wpb=235.6, bsz=16, num_updates=1200, lr=0.0005, gnorm=0.775, train_wall=6, gb_free=1.4, wall=91
epoch 002:    400 / 900 loss=0.427, ppl=1.34, wps=4209.6, ups=17.84, wpb=236, bsz=16, num_updates=1300, lr=0.0005, gnorm=0.919, train_wall=6, gb_free=1.4, wall=97
epoch 002:    400 / 900 loss=0.427, ppl=1.34, wps=4209.6, ups=17.84, wpb=236, bsz=16, num_updates=1300, lr=0.0005, gnorm=0.919, train_wall=6, gb_free=1.4, wall=97
epoch 002:    500 / 900 loss=0.385, ppl=1.31, wps=4221.1, ups=15.56, wpb=271.3, bsz=16, num_updates=1400, lr=0.0005, gnorm=0.786, train_wall=6, gb_free=1.4, wall=103
epoch 002:    500 / 900 loss=0.385, ppl=1.31, wps=4221.1, ups=15.56, wpb=271.3, bsz=16, num_updates=1400, lr=0.0005, gnorm=0.786, train_wall=6, gb_free=1.4, wall=103
epoch 002:    600 / 900 loss=0.297, ppl=1.23, wps=4201.1, ups=16.45, wpb=255.4, bsz=16, num_updates=1500, lr=0.0005, gnorm=0.814, train_wall=6, gb_free=1.4, wall=109
epoch 002:    600 / 900 loss=0.297, ppl=1.23, wps=4201.1, ups=16.45, wpb=255.4, bsz=16, num_updates=1500, lr=0.0005, gnorm=0.814, train_wall=6, gb_free=1.4, wall=109
epoch 002:    700 / 900 loss=0.294, ppl=1.23, wps=4306.4, ups=14.97, wpb=287.6, bsz=16, num_updates=1600, lr=0.0005, gnorm=0.843, train_wall=7, gb_free=1.4, wall=116
epoch 002:    700 / 900 loss=0.294, ppl=1.23, wps=4306.4, ups=14.97, wpb=287.6, bsz=16, num_updates=1600, lr=0.0005, gnorm=0.843, train_wall=7, gb_free=1.4, wall=116
epoch 002:    800 / 900 loss=0.219, ppl=1.16, wps=4336.2, ups=15.78, wpb=274.8, bsz=16, num_updates=1700, lr=0.0005, gnorm=0.549, train_wall=6, gb_free=1.4, wall=122
epoch 002:    800 / 900 loss=0.219, ppl=1.16, wps=4336.2, ups=15.78, wpb=274.8, bsz=16, num_updates=1700, lr=0.0005, gnorm=0.549, train_wall=6, gb_free=1.4, wall=122
epoch 002:    900 / 900 loss=0.177, ppl=1.13, wps=4165.2, ups=16.6, wpb=250.9, bsz=16, num_updates=1800, lr=0.0005, gnorm=0.803, train_wall=6, gb_free=1.4, wall=128
epoch 002:    900 / 900 loss=0.177, ppl=1.13, wps=4165.2, ups=16.6, wpb=250.9, bsz=16, num_updates=1800, lr=0.0005, gnorm=0.803, train_wall=6, gb_free=1.4, wall=128
begin validation on "valid" subset
epoch 002 | valid on 'valid' subset | loss 0.129 | ppl 1.09 | wps 17727.6 | wpb 264.7 | bsz 16 | num_updates 1800 | best_loss 0.129
epoch 002 | valid on 'valid' subset | loss 0.129 | ppl 1.09 | wps 17727.6 | wpb 264.7 | bsz 16 | num_updates 1800 | best_loss 0.129
end of epoch 2 (average epoch stats below)
epoch 002 | loss 0.383 | ppl 1.3 | wps 4074.1 | ups 15.55 | wpb 261.9 | bsz 16 | num_updates 1800 | lr 0.0005 | gnorm 0.785 | train_wall 55 | gb_free 1.4 | wall 130
epoch 002 | loss 0.383 | ppl 1.3 | wps 4074.1 | ups 15.55 | wpb 261.9 | bsz 16 | num_updates 1800 | lr 0.0005 | gnorm 0.785 | train_wall 55 | gb_free 1.4 | wall 130
Start iterating over samples
epoch 003:    100 / 900 loss=0.155, ppl=1.11, wps=3145.7, ups=12.25, wpb=256.9, bsz=16, num_updates=1900, lr=0.0005, gnorm=0.656, train_wall=6, gb_free=1.4, wall=136
epoch 003:    100 / 900 loss=0.155, ppl=1.11, wps=3145.7, ups=12.25, wpb=256.9, bsz=16, num_updates=1900, lr=0.0005, gnorm=0.656, train_wall=6, gb_free=1.4, wall=136
epoch 003:    100 / 900 loss=0.155, ppl=1.11, wps=3145.7, ups=12.25, wpb=256.9, bsz=16, num_updates=1900, lr=0.0005, gnorm=0.656, train_wall=6, gb_free=1.4, wall=136
epoch 003:    200 / 900 loss=0.144, ppl=1.1, wps=4138.9, ups=16.35, wpb=253.1, bsz=16, num_updates=2000, lr=0.0005, gnorm=0.517, train_wall=6, gb_free=1.4, wall=142
epoch 003:    200 / 900 loss=0.144, ppl=1.1, wps=4138.9, ups=16.35, wpb=253.1, bsz=16, num_updates=2000, lr=0.0005, gnorm=0.517, train_wall=6, gb_free=1.4, wall=142
epoch 003:    200 / 900 loss=0.144, ppl=1.1, wps=4138.9, ups=16.35, wpb=253.1, bsz=16, num_updates=2000, lr=0.0005, gnorm=0.517, train_wall=6, gb_free=1.4, wall=142
epoch 003:    300 / 900 loss=0.138, ppl=1.1, wps=4230.5, ups=15.23, wpb=277.8, bsz=16, num_updates=2100, lr=0.0005, gnorm=0.639, train_wall=6, gb_free=1.4, wall=149
epoch 003:    300 / 900 loss=0.138, ppl=1.1, wps=4230.5, ups=15.23, wpb=277.8, bsz=16, num_updates=2100, lr=0.0005, gnorm=0.639, train_wall=6, gb_free=1.4, wall=149
epoch 003:    300 / 900 loss=0.138, ppl=1.1, wps=4230.5, ups=15.23, wpb=277.8, bsz=16, num_updates=2100, lr=0.0005, gnorm=0.639, train_wall=6, gb_free=1.4, wall=149
epoch 003:    400 / 900 loss=0.14, ppl=1.1, wps=4309.6, ups=15.67, wpb=275, bsz=16, num_updates=2200, lr=0.0005, gnorm=0.616, train_wall=6, gb_free=1.4, wall=155
epoch 003:    400 / 900 loss=0.14, ppl=1.1, wps=4309.6, ups=15.67, wpb=275, bsz=16, num_updates=2200, lr=0.0005, gnorm=0.616, train_wall=6, gb_free=1.4, wall=155
epoch 003:    400 / 900 loss=0.14, ppl=1.1, wps=4309.6, ups=15.67, wpb=275, bsz=16, num_updates=2200, lr=0.0005, gnorm=0.616, train_wall=6, gb_free=1.4, wall=155
epoch 003:    500 / 900 loss=0.135, ppl=1.1, wps=4280.7, ups=16.07, wpb=266.4, bsz=16, num_updates=2300, lr=0.0005, gnorm=0.553, train_wall=6, gb_free=1.4, wall=162
epoch 003:    500 / 900 loss=0.135, ppl=1.1, wps=4280.7, ups=16.07, wpb=266.4, bsz=16, num_updates=2300, lr=0.0005, gnorm=0.553, train_wall=6, gb_free=1.4, wall=162
epoch 003:    500 / 900 loss=0.135, ppl=1.1, wps=4280.7, ups=16.07, wpb=266.4, bsz=16, num_updates=2300, lr=0.0005, gnorm=0.553, train_wall=6, gb_free=1.4, wall=162
epoch 003:    600 / 900 loss=0.102, ppl=1.07, wps=4142.8, ups=16.56, wpb=250.2, bsz=16, num_updates=2400, lr=0.0005, gnorm=0.594, train_wall=6, gb_free=1.4, wall=168
epoch 003:    600 / 900 loss=0.102, ppl=1.07, wps=4142.8, ups=16.56, wpb=250.2, bsz=16, num_updates=2400, lr=0.0005, gnorm=0.594, train_wall=6, gb_free=1.4, wall=168
epoch 003:    600 / 900 loss=0.102, ppl=1.07, wps=4142.8, ups=16.56, wpb=250.2, bsz=16, num_updates=2400, lr=0.0005, gnorm=0.594, train_wall=6, gb_free=1.4, wall=168
epoch 003:    700 / 900 loss=0.125, ppl=1.09, wps=4169.4, ups=15.9, wpb=262.2, bsz=16, num_updates=2500, lr=0.0005, gnorm=0.537, train_wall=6, gb_free=1.4, wall=174
epoch 003:    700 / 900 loss=0.125, ppl=1.09, wps=4169.4, ups=15.9, wpb=262.2, bsz=16, num_updates=2500, lr=0.0005, gnorm=0.537, train_wall=6, gb_free=1.4, wall=174
epoch 003:    700 / 900 loss=0.125, ppl=1.09, wps=4169.4, ups=15.9, wpb=262.2, bsz=16, num_updates=2500, lr=0.0005, gnorm=0.537, train_wall=6, gb_free=1.4, wall=174
epoch 003:    800 / 900 loss=0.083, ppl=1.06, wps=4324.9, ups=16.34, wpb=264.8, bsz=16, num_updates=2600, lr=0.0005, gnorm=0.413, train_wall=6, gb_free=1.4, wall=180
epoch 003:    800 / 900 loss=0.083, ppl=1.06, wps=4324.9, ups=16.34, wpb=264.8, bsz=16, num_updates=2600, lr=0.0005, gnorm=0.413, train_wall=6, gb_free=1.4, wall=180
epoch 003:    800 / 900 loss=0.083, ppl=1.06, wps=4324.9, ups=16.34, wpb=264.8, bsz=16, num_updates=2600, lr=0.0005, gnorm=0.413, train_wall=6, gb_free=1.4, wall=180
epoch 003:    900 / 900 loss=0.096, ppl=1.07, wps=4137.6, ups=16.48, wpb=251.1, bsz=16, num_updates=2700, lr=0.0005, gnorm=0.45, train_wall=6, gb_free=1.4, wall=186
epoch 003:    900 / 900 loss=0.096, ppl=1.07, wps=4137.6, ups=16.48, wpb=251.1, bsz=16, num_updates=2700, lr=0.0005, gnorm=0.45, train_wall=6, gb_free=1.4, wall=186
epoch 003:    900 / 900 loss=0.096, ppl=1.07, wps=4137.6, ups=16.48, wpb=251.1, bsz=16, num_updates=2700, lr=0.0005, gnorm=0.45, train_wall=6, gb_free=1.4, wall=186
begin validation on "valid" subset
epoch 003 | valid on 'valid' subset | loss 0.078 | ppl 1.06 | wps 17552.4 | wpb 264.7 | bsz 16 | num_updates 2700 | best_loss 0.078
epoch 003 | valid on 'valid' subset | loss 0.078 | ppl 1.06 | wps 17552.4 | wpb 264.7 | bsz 16 | num_updates 2700 | best_loss 0.078
epoch 003 | valid on 'valid' subset | loss 0.078 | ppl 1.06 | wps 17552.4 | wpb 264.7 | bsz 16 | num_updates 2700 | best_loss 0.078
end of epoch 3 (average epoch stats below)
epoch 003 | loss 0.124 | ppl 1.09 | wps 4062.4 | ups 15.51 | wpb 261.9 | bsz 16 | num_updates 2700 | lr 0.0005 | gnorm 0.553 | train_wall 55 | gb_free 1.4 | wall 188
epoch 003 | loss 0.124 | ppl 1.09 | wps 4062.4 | ups 15.51 | wpb 261.9 | bsz 16 | num_updates 2700 | lr 0.0005 | gnorm 0.553 | train_wall 55 | gb_free 1.4 | wall 188
epoch 003 | loss 0.124 | ppl 1.09 | wps 4062.4 | ups 15.51 | wpb 261.9 | bsz 16 | num_updates 2700 | lr 0.0005 | gnorm 0.553 | train_wall 55 | gb_free 1.4 | wall 188
Start iterating over samples
epoch 004:    100 / 900 loss=0.08, ppl=1.06, wps=3042.4, ups=11.52, wpb=264.1, bsz=16, num_updates=2800, lr=0.0005, gnorm=0.465, train_wall=6, gb_free=1.4, wall=195
epoch 004:    100 / 900 loss=0.08, ppl=1.06, wps=3042.4, ups=11.52, wpb=264.1, bsz=16, num_updates=2800, lr=0.0005, gnorm=0.465, train_wall=6, gb_free=1.4, wall=195
epoch 004:    100 / 900 loss=0.08, ppl=1.06, wps=3042.4, ups=11.52, wpb=264.1, bsz=16, num_updates=2800, lr=0.0005, gnorm=0.465, train_wall=6, gb_free=1.4, wall=195
epoch 004:    100 / 900 loss=0.08, ppl=1.06, wps=3042.4, ups=11.52, wpb=264.1, bsz=16, num_updates=2800, lr=0.0005, gnorm=0.465, train_wall=6, gb_free=1.4, wall=195
epoch 004:    200 / 900 loss=0.107, ppl=1.08, wps=4185.5, ups=15.1, wpb=277.2, bsz=16, num_updates=2900, lr=0.0005, gnorm=0.591, train_wall=7, gb_free=1.4, wall=201
epoch 004:    200 / 900 loss=0.107, ppl=1.08, wps=4185.5, ups=15.1, wpb=277.2, bsz=16, num_updates=2900, lr=0.0005, gnorm=0.591, train_wall=7, gb_free=1.4, wall=201
epoch 004:    200 / 900 loss=0.107, ppl=1.08, wps=4185.5, ups=15.1, wpb=277.2, bsz=16, num_updates=2900, lr=0.0005, gnorm=0.591, train_wall=7, gb_free=1.4, wall=201
epoch 004:    200 / 900 loss=0.107, ppl=1.08, wps=4185.5, ups=15.1, wpb=277.2, bsz=16, num_updates=2900, lr=0.0005, gnorm=0.591, train_wall=7, gb_free=1.4, wall=201
epoch 004:    300 / 900 loss=0.078, ppl=1.06, wps=4362.2, ups=16.44, wpb=265.3, bsz=16, num_updates=3000, lr=0.0005, gnorm=0.384, train_wall=6, gb_free=1.4, wall=207
epoch 004:    300 / 900 loss=0.078, ppl=1.06, wps=4362.2, ups=16.44, wpb=265.3, bsz=16, num_updates=3000, lr=0.0005, gnorm=0.384, train_wall=6, gb_free=1.4, wall=207
epoch 004:    300 / 900 loss=0.078, ppl=1.06, wps=4362.2, ups=16.44, wpb=265.3, bsz=16, num_updates=3000, lr=0.0005, gnorm=0.384, train_wall=6, gb_free=1.4, wall=207
epoch 004:    300 / 900 loss=0.078, ppl=1.06, wps=4362.2, ups=16.44, wpb=265.3, bsz=16, num_updates=3000, lr=0.0005, gnorm=0.384, train_wall=6, gb_free=1.4, wall=207
epoch 004:    400 / 900 loss=0.076, ppl=1.05, wps=4341.8, ups=16.23, wpb=267.5, bsz=16, num_updates=3100, lr=0.0005, gnorm=0.724, train_wall=6, gb_free=1.4, wall=214
epoch 004:    400 / 900 loss=0.076, ppl=1.05, wps=4341.8, ups=16.23, wpb=267.5, bsz=16, num_updates=3100, lr=0.0005, gnorm=0.724, train_wall=6, gb_free=1.4, wall=214
epoch 004:    400 / 900 loss=0.076, ppl=1.05, wps=4341.8, ups=16.23, wpb=267.5, bsz=16, num_updates=3100, lr=0.0005, gnorm=0.724, train_wall=6, gb_free=1.4, wall=214
epoch 004:    400 / 900 loss=0.076, ppl=1.05, wps=4341.8, ups=16.23, wpb=267.5, bsz=16, num_updates=3100, lr=0.0005, gnorm=0.724, train_wall=6, gb_free=1.4, wall=214
epoch 004:    500 / 900 loss=0.077, ppl=1.06, wps=4300.1, ups=15.71, wpb=273.8, bsz=16, num_updates=3200, lr=0.0005, gnorm=0.348, train_wall=6, gb_free=1.4, wall=220
epoch 004:    500 / 900 loss=0.077, ppl=1.06, wps=4300.1, ups=15.71, wpb=273.8, bsz=16, num_updates=3200, lr=0.0005, gnorm=0.348, train_wall=6, gb_free=1.4, wall=220
epoch 004:    500 / 900 loss=0.077, ppl=1.06, wps=4300.1, ups=15.71, wpb=273.8, bsz=16, num_updates=3200, lr=0.0005, gnorm=0.348, train_wall=6, gb_free=1.4, wall=220
epoch 004:    500 / 900 loss=0.077, ppl=1.06, wps=4300.1, ups=15.71, wpb=273.8, bsz=16, num_updates=3200, lr=0.0005, gnorm=0.348, train_wall=6, gb_free=1.4, wall=220
epoch 004:    600 / 900 loss=0.065, ppl=1.05, wps=4205.8, ups=17.2, wpb=244.5, bsz=16, num_updates=3300, lr=0.0005, gnorm=0.259, train_wall=6, gb_free=1.4, wall=226
epoch 004:    600 / 900 loss=0.065, ppl=1.05, wps=4205.8, ups=17.2, wpb=244.5, bsz=16, num_updates=3300, lr=0.0005, gnorm=0.259, train_wall=6, gb_free=1.4, wall=226
epoch 004:    600 / 900 loss=0.065, ppl=1.05, wps=4205.8, ups=17.2, wpb=244.5, bsz=16, num_updates=3300, lr=0.0005, gnorm=0.259, train_wall=6, gb_free=1.4, wall=226
epoch 004:    600 / 900 loss=0.065, ppl=1.05, wps=4205.8, ups=17.2, wpb=244.5, bsz=16, num_updates=3300, lr=0.0005, gnorm=0.259, train_wall=6, gb_free=1.4, wall=226
epoch 004:    700 / 900 loss=0.067, ppl=1.05, wps=4256.1, ups=15.87, wpb=268.2, bsz=16, num_updates=3400, lr=0.0005, gnorm=0.354, train_wall=6, gb_free=1.4, wall=232
epoch 004:    700 / 900 loss=0.067, ppl=1.05, wps=4256.1, ups=15.87, wpb=268.2, bsz=16, num_updates=3400, lr=0.0005, gnorm=0.354, train_wall=6, gb_free=1.4, wall=232
epoch 004:    700 / 900 loss=0.067, ppl=1.05, wps=4256.1, ups=15.87, wpb=268.2, bsz=16, num_updates=3400, lr=0.0005, gnorm=0.354, train_wall=6, gb_free=1.4, wall=232
epoch 004:    700 / 900 loss=0.067, ppl=1.05, wps=4256.1, ups=15.87, wpb=268.2, bsz=16, num_updates=3400, lr=0.0005, gnorm=0.354, train_wall=6, gb_free=1.4, wall=232
epoch 004:    800 / 900 loss=0.064, ppl=1.05, wps=4085.3, ups=16.65, wpb=245.4, bsz=16, num_updates=3500, lr=0.0005, gnorm=0.31, train_wall=6, gb_free=1.4, wall=238
epoch 004:    800 / 900 loss=0.064, ppl=1.05, wps=4085.3, ups=16.65, wpb=245.4, bsz=16, num_updates=3500, lr=0.0005, gnorm=0.31, train_wall=6, gb_free=1.4, wall=238
epoch 004:    800 / 900 loss=0.064, ppl=1.05, wps=4085.3, ups=16.65, wpb=245.4, bsz=16, num_updates=3500, lr=0.0005, gnorm=0.31, train_wall=6, gb_free=1.4, wall=238
epoch 004:    800 / 900 loss=0.064, ppl=1.05, wps=4085.3, ups=16.65, wpb=245.4, bsz=16, num_updates=3500, lr=0.0005, gnorm=0.31, train_wall=6, gb_free=1.4, wall=238
epoch 004:    900 / 900 loss=0.073, ppl=1.05, wps=4125.6, ups=16.4, wpb=251.5, bsz=16, num_updates=3600, lr=0.0005, gnorm=0.325, train_wall=6, gb_free=1.4, wall=244
epoch 004:    900 / 900 loss=0.073, ppl=1.05, wps=4125.6, ups=16.4, wpb=251.5, bsz=16, num_updates=3600, lr=0.0005, gnorm=0.325, train_wall=6, gb_free=1.4, wall=244
epoch 004:    900 / 900 loss=0.073, ppl=1.05, wps=4125.6, ups=16.4, wpb=251.5, bsz=16, num_updates=3600, lr=0.0005, gnorm=0.325, train_wall=6, gb_free=1.4, wall=244
epoch 004:    900 / 900 loss=0.073, ppl=1.05, wps=4125.6, ups=16.4, wpb=251.5, bsz=16, num_updates=3600, lr=0.0005, gnorm=0.325, train_wall=6, gb_free=1.4, wall=244
begin validation on "valid" subset
epoch 004 | valid on 'valid' subset | loss 0.05 | ppl 1.04 | wps 17715.3 | wpb 264.7 | bsz 16 | num_updates 3600 | best_loss 0.05
epoch 004 | valid on 'valid' subset | loss 0.05 | ppl 1.04 | wps 17715.3 | wpb 264.7 | bsz 16 | num_updates 3600 | best_loss 0.05
epoch 004 | valid on 'valid' subset | loss 0.05 | ppl 1.04 | wps 17715.3 | wpb 264.7 | bsz 16 | num_updates 3600 | best_loss 0.05
epoch 004 | valid on 'valid' subset | loss 0.05 | ppl 1.04 | wps 17715.3 | wpb 264.7 | bsz 16 | num_updates 3600 | best_loss 0.05
end of epoch 4 (average epoch stats below)
epoch 004 | loss 0.077 | ppl 1.05 | wps 4058.1 | ups 15.49 | wpb 261.9 | bsz 16 | num_updates 3600 | lr 0.0005 | gnorm 0.418 | train_wall 55 | gb_free 1.4 | wall 246
epoch 004 | loss 0.077 | ppl 1.05 | wps 4058.1 | ups 15.49 | wpb 261.9 | bsz 16 | num_updates 3600 | lr 0.0005 | gnorm 0.418 | train_wall 55 | gb_free 1.4 | wall 246
epoch 004 | loss 0.077 | ppl 1.05 | wps 4058.1 | ups 15.49 | wpb 261.9 | bsz 16 | num_updates 3600 | lr 0.0005 | gnorm 0.418 | train_wall 55 | gb_free 1.4 | wall 246
epoch 004 | loss 0.077 | ppl 1.05 | wps 4058.1 | ups 15.49 | wpb 261.9 | bsz 16 | num_updates 3600 | lr 0.0005 | gnorm 0.418 | train_wall 55 | gb_free 1.4 | wall 246
Start iterating over samples
epoch 005:    100 / 900 loss=0.04, ppl=1.03, wps=3116.2, ups=12.34, wpb=252.5, bsz=16, num_updates=3700, lr=0.0005, gnorm=0.222, train_wall=6, gb_free=1.4, wall=252
epoch 005:    100 / 900 loss=0.04, ppl=1.03, wps=3116.2, ups=12.34, wpb=252.5, bsz=16, num_updates=3700, lr=0.0005, gnorm=0.222, train_wall=6, gb_free=1.4, wall=252
epoch 005:    100 / 900 loss=0.04, ppl=1.03, wps=3116.2, ups=12.34, wpb=252.5, bsz=16, num_updates=3700, lr=0.0005, gnorm=0.222, train_wall=6, gb_free=1.4, wall=252
epoch 005:    100 / 900 loss=0.04, ppl=1.03, wps=3116.2, ups=12.34, wpb=252.5, bsz=16, num_updates=3700, lr=0.0005, gnorm=0.222, train_wall=6, gb_free=1.4, wall=252
epoch 005:    100 / 900 loss=0.04, ppl=1.03, wps=3116.2, ups=12.34, wpb=252.5, bsz=16, num_updates=3700, lr=0.0005, gnorm=0.222, train_wall=6, gb_free=1.4, wall=252
epoch 005:    200 / 900 loss=0.061, ppl=1.04, wps=4165.6, ups=15.22, wpb=273.7, bsz=16, num_updates=3800, lr=0.0005, gnorm=0.453, train_wall=6, gb_free=1.4, wall=259
epoch 005:    200 / 900 loss=0.061, ppl=1.04, wps=4165.6, ups=15.22, wpb=273.7, bsz=16, num_updates=3800, lr=0.0005, gnorm=0.453, train_wall=6, gb_free=1.4, wall=259
epoch 005:    200 / 900 loss=0.061, ppl=1.04, wps=4165.6, ups=15.22, wpb=273.7, bsz=16, num_updates=3800, lr=0.0005, gnorm=0.453, train_wall=6, gb_free=1.4, wall=259
epoch 005:    200 / 900 loss=0.061, ppl=1.04, wps=4165.6, ups=15.22, wpb=273.7, bsz=16, num_updates=3800, lr=0.0005, gnorm=0.453, train_wall=6, gb_free=1.4, wall=259
epoch 005:    200 / 900 loss=0.061, ppl=1.04, wps=4165.6, ups=15.22, wpb=273.7, bsz=16, num_updates=3800, lr=0.0005, gnorm=0.453, train_wall=6, gb_free=1.4, wall=259
epoch 005:    300 / 900 loss=0.064, ppl=1.05, wps=4066.3, ups=15.85, wpb=256.5, bsz=16, num_updates=3900, lr=0.0005, gnorm=0.333, train_wall=6, gb_free=1.4, wall=265
epoch 005:    300 / 900 loss=0.064, ppl=1.05, wps=4066.3, ups=15.85, wpb=256.5, bsz=16, num_updates=3900, lr=0.0005, gnorm=0.333, train_wall=6, gb_free=1.4, wall=265
epoch 005:    300 / 900 loss=0.064, ppl=1.05, wps=4066.3, ups=15.85, wpb=256.5, bsz=16, num_updates=3900, lr=0.0005, gnorm=0.333, train_wall=6, gb_free=1.4, wall=265
epoch 005:    300 / 900 loss=0.064, ppl=1.05, wps=4066.3, ups=15.85, wpb=256.5, bsz=16, num_updates=3900, lr=0.0005, gnorm=0.333, train_wall=6, gb_free=1.4, wall=265
epoch 005:    300 / 900 loss=0.064, ppl=1.05, wps=4066.3, ups=15.85, wpb=256.5, bsz=16, num_updates=3900, lr=0.0005, gnorm=0.333, train_wall=6, gb_free=1.4, wall=265
epoch 005:    400 / 900 loss=0.038, ppl=1.03, wps=4330.3, ups=16.16, wpb=268, bsz=16, num_updates=4000, lr=0.0005, gnorm=0.287, train_wall=6, gb_free=1.4, wall=271
epoch 005:    400 / 900 loss=0.038, ppl=1.03, wps=4330.3, ups=16.16, wpb=268, bsz=16, num_updates=4000, lr=0.0005, gnorm=0.287, train_wall=6, gb_free=1.4, wall=271
epoch 005:    400 / 900 loss=0.038, ppl=1.03, wps=4330.3, ups=16.16, wpb=268, bsz=16, num_updates=4000, lr=0.0005, gnorm=0.287, train_wall=6, gb_free=1.4, wall=271
epoch 005:    400 / 900 loss=0.038, ppl=1.03, wps=4330.3, ups=16.16, wpb=268, bsz=16, num_updates=4000, lr=0.0005, gnorm=0.287, train_wall=6, gb_free=1.4, wall=271
epoch 005:    400 / 900 loss=0.038, ppl=1.03, wps=4330.3, ups=16.16, wpb=268, bsz=16, num_updates=4000, lr=0.0005, gnorm=0.287, train_wall=6, gb_free=1.4, wall=271
epoch 005:    500 / 900 loss=0.057, ppl=1.04, wps=4270.1, ups=16.01, wpb=266.7, bsz=16, num_updates=4100, lr=0.0005, gnorm=0.413, train_wall=6, gb_free=1.4, wall=278
epoch 005:    500 / 900 loss=0.057, ppl=1.04, wps=4270.1, ups=16.01, wpb=266.7, bsz=16, num_updates=4100, lr=0.0005, gnorm=0.413, train_wall=6, gb_free=1.4, wall=278
epoch 005:    500 / 900 loss=0.057, ppl=1.04, wps=4270.1, ups=16.01, wpb=266.7, bsz=16, num_updates=4100, lr=0.0005, gnorm=0.413, train_wall=6, gb_free=1.4, wall=278
epoch 005:    500 / 900 loss=0.057, ppl=1.04, wps=4270.1, ups=16.01, wpb=266.7, bsz=16, num_updates=4100, lr=0.0005, gnorm=0.413, train_wall=6, gb_free=1.4, wall=278
epoch 005:    500 / 900 loss=0.057, ppl=1.04, wps=4270.1, ups=16.01, wpb=266.7, bsz=16, num_updates=4100, lr=0.0005, gnorm=0.413, train_wall=6, gb_free=1.4, wall=278
epoch 005:    600 / 900 loss=0.075, ppl=1.05, wps=4222.2, ups=16.23, wpb=260.2, bsz=16, num_updates=4200, lr=0.0005, gnorm=0.534, train_wall=6, gb_free=1.4, wall=284
epoch 005:    600 / 900 loss=0.075, ppl=1.05, wps=4222.2, ups=16.23, wpb=260.2, bsz=16, num_updates=4200, lr=0.0005, gnorm=0.534, train_wall=6, gb_free=1.4, wall=284
epoch 005:    600 / 900 loss=0.075, ppl=1.05, wps=4222.2, ups=16.23, wpb=260.2, bsz=16, num_updates=4200, lr=0.0005, gnorm=0.534, train_wall=6, gb_free=1.4, wall=284
epoch 005:    600 / 900 loss=0.075, ppl=1.05, wps=4222.2, ups=16.23, wpb=260.2, bsz=16, num_updates=4200, lr=0.0005, gnorm=0.534, train_wall=6, gb_free=1.4, wall=284
epoch 005:    600 / 900 loss=0.075, ppl=1.05, wps=4222.2, ups=16.23, wpb=260.2, bsz=16, num_updates=4200, lr=0.0005, gnorm=0.534, train_wall=6, gb_free=1.4, wall=284
epoch 005:    700 / 900 loss=0.035, ppl=1.02, wps=4257.1, ups=16.54, wpb=257.4, bsz=16, num_updates=4300, lr=0.0005, gnorm=0.297, train_wall=6, gb_free=1.4, wall=290
epoch 005:    700 / 900 loss=0.035, ppl=1.02, wps=4257.1, ups=16.54, wpb=257.4, bsz=16, num_updates=4300, lr=0.0005, gnorm=0.297, train_wall=6, gb_free=1.4, wall=290
epoch 005:    700 / 900 loss=0.035, ppl=1.02, wps=4257.1, ups=16.54, wpb=257.4, bsz=16, num_updates=4300, lr=0.0005, gnorm=0.297, train_wall=6, gb_free=1.4, wall=290
epoch 005:    700 / 900 loss=0.035, ppl=1.02, wps=4257.1, ups=16.54, wpb=257.4, bsz=16, num_updates=4300, lr=0.0005, gnorm=0.297, train_wall=6, gb_free=1.4, wall=290
epoch 005:    700 / 900 loss=0.035, ppl=1.02, wps=4257.1, ups=16.54, wpb=257.4, bsz=16, num_updates=4300, lr=0.0005, gnorm=0.297, train_wall=6, gb_free=1.4, wall=290
epoch 005:    800 / 900 loss=0.036, ppl=1.03, wps=4319.7, ups=15.26, wpb=283.1, bsz=16, num_updates=4400, lr=0.0005, gnorm=0.229, train_wall=6, gb_free=1.4, wall=296
epoch 005:    800 / 900 loss=0.036, ppl=1.03, wps=4319.7, ups=15.26, wpb=283.1, bsz=16, num_updates=4400, lr=0.0005, gnorm=0.229, train_wall=6, gb_free=1.4, wall=296
epoch 005:    800 / 900 loss=0.036, ppl=1.03, wps=4319.7, ups=15.26, wpb=283.1, bsz=16, num_updates=4400, lr=0.0005, gnorm=0.229, train_wall=6, gb_free=1.4, wall=296
epoch 005:    800 / 900 loss=0.036, ppl=1.03, wps=4319.7, ups=15.26, wpb=283.1, bsz=16, num_updates=4400, lr=0.0005, gnorm=0.229, train_wall=6, gb_free=1.4, wall=296
epoch 005:    800 / 900 loss=0.036, ppl=1.03, wps=4319.7, ups=15.26, wpb=283.1, bsz=16, num_updates=4400, lr=0.0005, gnorm=0.229, train_wall=6, gb_free=1.4, wall=296
epoch 005:    900 / 900 loss=0.038, ppl=1.03, wps=4061.7, ups=16.97, wpb=239.3, bsz=16, num_updates=4500, lr=0.0005, gnorm=0.352, train_wall=6, gb_free=1.4, wall=302
epoch 005:    900 / 900 loss=0.038, ppl=1.03, wps=4061.7, ups=16.97, wpb=239.3, bsz=16, num_updates=4500, lr=0.0005, gnorm=0.352, train_wall=6, gb_free=1.4, wall=302
epoch 005:    900 / 900 loss=0.038, ppl=1.03, wps=4061.7, ups=16.97, wpb=239.3, bsz=16, num_updates=4500, lr=0.0005, gnorm=0.352, train_wall=6, gb_free=1.4, wall=302
epoch 005:    900 / 900 loss=0.038, ppl=1.03, wps=4061.7, ups=16.97, wpb=239.3, bsz=16, num_updates=4500, lr=0.0005, gnorm=0.352, train_wall=6, gb_free=1.4, wall=302
epoch 005:    900 / 900 loss=0.038, ppl=1.03, wps=4061.7, ups=16.97, wpb=239.3, bsz=16, num_updates=4500, lr=0.0005, gnorm=0.352, train_wall=6, gb_free=1.4, wall=302
begin validation on "valid" subset
epoch 005 | valid on 'valid' subset | loss 0.033 | ppl 1.02 | wps 17556.2 | wpb 264.7 | bsz 16 | num_updates 4500 | best_loss 0.033
epoch 005 | valid on 'valid' subset | loss 0.033 | ppl 1.02 | wps 17556.2 | wpb 264.7 | bsz 16 | num_updates 4500 | best_loss 0.033
epoch 005 | valid on 'valid' subset | loss 0.033 | ppl 1.02 | wps 17556.2 | wpb 264.7 | bsz 16 | num_updates 4500 | best_loss 0.033
epoch 005 | valid on 'valid' subset | loss 0.033 | ppl 1.02 | wps 17556.2 | wpb 264.7 | bsz 16 | num_updates 4500 | best_loss 0.033
epoch 005 | valid on 'valid' subset | loss 0.033 | ppl 1.02 | wps 17556.2 | wpb 264.7 | bsz 16 | num_updates 4500 | best_loss 0.033
end of epoch 5 (average epoch stats below)
epoch 005 | loss 0.05 | ppl 1.03 | wps 4041.7 | ups 15.43 | wpb 261.9 | bsz 16 | num_updates 4500 | lr 0.0005 | gnorm 0.347 | train_wall 55 | gb_free 1.4 | wall 305
epoch 005 | loss 0.05 | ppl 1.03 | wps 4041.7 | ups 15.43 | wpb 261.9 | bsz 16 | num_updates 4500 | lr 0.0005 | gnorm 0.347 | train_wall 55 | gb_free 1.4 | wall 305
epoch 005 | loss 0.05 | ppl 1.03 | wps 4041.7 | ups 15.43 | wpb 261.9 | bsz 16 | num_updates 4500 | lr 0.0005 | gnorm 0.347 | train_wall 55 | gb_free 1.4 | wall 305
epoch 005 | loss 0.05 | ppl 1.03 | wps 4041.7 | ups 15.43 | wpb 261.9 | bsz 16 | num_updates 4500 | lr 0.0005 | gnorm 0.347 | train_wall 55 | gb_free 1.4 | wall 305
epoch 005 | loss 0.05 | ppl 1.03 | wps 4041.7 | ups 15.43 | wpb 261.9 | bsz 16 | num_updates 4500 | lr 0.0005 | gnorm 0.347 | train_wall 55 | gb_free 1.4 | wall 305
done training in 303.3 seconds
